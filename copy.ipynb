{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de631904-6a18-4c0e-bfe8-359cda3e251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5820057-2757-470f-b25c-daf1de66e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function to filter out corrupted images\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Custom loader to handle corrupted images\n",
    "def safe_loader(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert(\"RGB\")\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Skipping corrupted image: {path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8cb48a-afed-40e3-94fa-69e9114deca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the paths to img folders\n",
    "train_dir = '/home/arnav/Documents/research_project/assignment1/images/train'\n",
    "test_dir = '/home/arnav/Documents/research_project/assignment1/images/test'\n",
    "val_dir = '/home/arnav/Documents/research_project/assignment1/images/val'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf9bd0-fb76-4b83-a55e-6a7c1a9823ba",
   "metadata": {},
   "source": [
    "\n",
    "1.(b) Use the image transforms to resize the images to size 64 × 64, followed by the normalization\n",
    "of every image using mean: [0.485, 0.456, 0.406] and standard deviation:\n",
    "[0.229,0.224,0.225].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d60f2e-30cb-4e76-8d65-08e2db1414e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ive used .Compose to group transforms together\n",
    "transform = transforms.Compose([transforms.Resize((64,64)),\n",
    "                                transforms.ToTensor(), #Convert a PIL Image or ndarray to tensor and scale the values accordingly, this transformation scales the pixel values from the range [0, 255] to the range [0, 1].\n",
    "                               transforms.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) #Normalize a tensor image with mean and standard deviation. Mean normalization: Subtracts the mean value from each channel (R, G, B) of the image tensor.Standard deviation normalization: Divides each channel by its standard deviation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00582920-04af-471f-be3e-2b4fff1d272a",
   "metadata": {},
   "source": [
    "1.(c)Read the training, validation and test data from their respective folders using “Imagefolder”\n",
    "and “DataLoader” packages defined in torchvision and torch after fixing the batch size as 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06018f64-94d0-4146-94e1-4063e9b49d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root= train_dir, transform=transform, loader= safe_loader)\n",
    "test_data = datasets.ImageFolder(root= test_dir, transform=transform, loader = safe_loader)\n",
    "val_data = datasets.ImageFolder(root= val_dir, transform=transform, loader = safe_loader)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca6141-ac17-48ab-bc9e-bd4aa797f96b",
   "metadata": {},
   "source": [
    "    The shuffle parameter controls whether the data should be shuffled at the beginning of each epoch:\n",
    "\n",
    "    Training Data (shuffle=True): Shuffling the training data ensures that the model does not learn the order of the data, which could lead to overfitting. \n",
    "    It helps in providing the model with a varied distribution of samples in each batch, leading to better generalization.\n",
    "    \n",
    "    Validation and Test Data (shuffle=False): For validation and test data, shuffling is typically not necessary.\n",
    "    The purpose of these datasets is to evaluate the model's performance on unseen data.\n",
    "    Shuffling the validation and test data does not affect the evaluation metrics but keeping the order can sometimes help in debugging and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de97572-83dc-49ed-8ed1-d78ef15c9437",
   "metadata": {},
   "source": [
    "1.(d) Define the simple network architecture using the three linear layers: L1 ; L2 and L3 using\n",
    "arguments (12288, 84); (84,50) and (50,2) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e8ed73-55bd-458b-8c2d-2f2921d62836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.l1 = nn.Linear(64*64*3, 84) #first layer\n",
    "        self.l2 = nn.Linear(84, 50)\n",
    "        self.l3 = nn.Linear(50,2)\n",
    "        self.relu = nn.ReLU() #Rectified Linear Units: activation function. simply returns max(0,x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= x.view(x.size(0), -1) # reshapes the input tensor to have the shape (batch_size, num_features), where num_features is the product of the dimensions of the image.\n",
    "        x = self.relu(self.l1(x)) #pass the flattened input through first layer\n",
    "        x = self.relu(self.l2(x))\n",
    "        x = self.l3(x) # passes the output of the second layer through the third fully connected layer, This layer does not have an activation function applied, as it directly outputs the raw scores (logits) for the two classes (cat and fish)\n",
    "\n",
    "        return x  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc52cb-301c-4186-a2ea-ef03cd8b823c",
   "metadata": {},
   "source": [
    "1.(e) Use the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a485c86-9a6e-46de-9504-b7577a7bf40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet\n",
    "\n",
    "class CustomAlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomAlexNet, self).__init__()\n",
    "        self.alexnet = alexnet(pretrained=False)\n",
    "        self.alexnet.classifier[6] = nn.Linear(4096, 2)#replaced the 6th and final layer of the alexnet classifier with a layer that outputs 2 classes (cat and fish)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.alexnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514c9c6-de67-4603-96b7-9688473cc42f",
   "metadata": {},
   "source": [
    "1.(f) Copy the model to GPU and complete the training function below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d2dfcc-3d0c-4580-a9fb-7ae72b6abaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef train(model, optimizer, loss_fn, train_loader, val_loader, epochs=25, device=”cpu”):\\n...\\n...\\nfor epoch in range(1, epochs + 1):\\n....\\nmodel.train()\\nfor batch in train_loader:\\n...\\n...\\n...\\nmodel.eval()\\n...\\n...\\nfor batch in val_loader:\\n...\\n...\\n...\\ng)print(epoch, training_loss, val_loss, accuracy)\\nprint(average_accuracy)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=25, device=”cpu”):\n",
    "...\n",
    "...\n",
    "for epoch in range(1, epochs + 1):\n",
    "....\n",
    "model.train()\n",
    "for batch in train_loader:\n",
    "...\n",
    "...\n",
    "...\n",
    "model.eval()\n",
    "...\n",
    "...\n",
    "for batch in val_loader:\n",
    "...\n",
    "...\n",
    "...\n",
    "g)print(epoch, training_loss, val_loss, accuracy)\n",
    "print(average_accuracy)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7235c6e-b361-48da-859a-a36a2cf598d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=25, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        model.train()  # Setting the model to train mode\n",
    "        training_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in train_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Set gradient to zero\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()  # Loss.item() converts the loss tensor to a standard Python number (float)\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        train_accuracy = correct / total\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        model.eval()  # Setting the model to validation mode\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation during validation, which saves memory and computation time\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                \n",
    "        val_accuracy = correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Loss: {training_loss / len(train_loader)}, Train Accuracy: {train_accuracy}, Val Loss: {val_loss / len(val_loader)}, Val Accuracy: {val_accuracy}\")\n",
    "\n",
    "    avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "    avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "    print(f\"Average Training Accuracy over {epochs} epochs: {avg_train_accuracy}\")\n",
    "    print(f\"Average Validation Accuracy over {epochs} epochs: {avg_val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab58cd88-42c0-4b73-900e-5cd8a6c03219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Loss: {test_loss / len(test_loader)}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb519d-2311-4160-ba48-d4bb0aaa84c2",
   "metadata": {},
   "source": [
    "1.(h) Tweak the following parameters for both the simple network and AlexNet:\n",
    "1) Learning rate: 0.1, 0.01, 0.001, 0.0001\n",
    "2) Batch size: 8, 16, 32, 64, 128\n",
    "3) Activation functions: ReLU, GeLU, SeLU , SiLU, Sigmoid\n",
    "4) Epochs: 25, 50, 100\n",
    "5) Number of input/output features only for simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa3cd018-ac9f-46c7-b204-06717b865536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6165532523935492, Train Accuracy: 0.6838905775075987, Val Loss: 0.48925653100013733, Val Accuracy: 0.776595744680851\n",
      "Epoch 2: Train Loss: 0.49354498223824933, Train Accuracy: 0.7781155015197568, Val Loss: 0.4168281067501415, Val Accuracy: 0.817629179331307\n",
      "Epoch 3: Train Loss: 0.422606267712333, Train Accuracy: 0.8161094224924013, Val Loss: 0.36442464048212225, Val Accuracy: 0.8465045592705167\n",
      "Epoch 4: Train Loss: 0.3689033199440349, Train Accuracy: 0.8358662613981763, Val Loss: 0.33533755757591943, Val Accuracy: 0.8662613981762918\n",
      "Epoch 5: Train Loss: 0.36865936626087537, Train Accuracy: 0.8586626139817629, Val Loss: 0.30072188648310577, Val Accuracy: 0.89209726443769\n",
      "Epoch 6: Train Loss: 0.31133536858992145, Train Accuracy: 0.89209726443769, Val Loss: 0.2669908052141016, Val Accuracy: 0.9057750759878419\n",
      "Epoch 7: Train Loss: 0.2697857049378482, Train Accuracy: 0.9072948328267477, Val Loss: 0.23848506130955435, Val Accuracy: 0.9270516717325228\n",
      "Epoch 8: Train Loss: 0.23812169242988934, Train Accuracy: 0.9285714285714286, Val Loss: 0.21545046296986667, Val Accuracy: 0.9361702127659575\n",
      "Epoch 9: Train Loss: 0.21870289878411728, Train Accuracy: 0.9376899696048632, Val Loss: 0.19595674018968234, Val Accuracy: 0.9483282674772037\n",
      "Epoch 10: Train Loss: 0.2111473638903011, Train Accuracy: 0.9498480243161094, Val Loss: 0.17269994183020157, Val Accuracy: 0.9635258358662614\n",
      "Epoch 11: Train Loss: 0.17440423437140204, Train Accuracy: 0.9635258358662614, Val Loss: 0.15416395325552334, Val Accuracy: 0.9696048632218845\n",
      "Epoch 12: Train Loss: 0.15410021827979523, Train Accuracy: 0.9650455927051672, Val Loss: 0.13711473887616937, Val Accuracy: 0.9696048632218845\n",
      "Epoch 13: Train Loss: 0.1431320844726129, Train Accuracy: 0.9711246200607903, Val Loss: 0.12334040891040456, Val Accuracy: 0.9756838905775076\n",
      "Epoch 14: Train Loss: 0.1268765005198392, Train Accuracy: 0.9772036474164134, Val Loss: 0.11125075715509328, Val Accuracy: 0.9848024316109423\n",
      "Epoch 15: Train Loss: 0.1155238923701373, Train Accuracy: 0.9832826747720365, Val Loss: 0.10469668121500449, Val Accuracy: 0.9817629179331308\n",
      "Epoch 16: Train Loss: 0.11276584050872109, Train Accuracy: 0.9893617021276596, Val Loss: 0.09733713045716286, Val Accuracy: 0.9848024316109423\n",
      "Epoch 17: Train Loss: 0.1013661880384792, Train Accuracy: 0.986322188449848, Val Loss: 0.08567278899929741, Val Accuracy: 0.993920972644377\n",
      "Epoch 18: Train Loss: 0.08762765608050606, Train Accuracy: 0.9924012158054711, Val Loss: 0.07700695740905675, Val Accuracy: 0.9924012158054711\n",
      "Epoch 19: Train Loss: 0.07661661979827014, Train Accuracy: 0.9924012158054711, Val Loss: 0.06656782938675447, Val Accuracy: 0.993920972644377\n",
      "Epoch 20: Train Loss: 0.06810145655816252, Train Accuracy: 0.993920972644377, Val Loss: 0.05954412286254493, Val Accuracy: 0.9954407294832827\n",
      "Epoch 21: Train Loss: 0.061258251016790215, Train Accuracy: 0.9954407294832827, Val Loss: 0.05402366664599289, Val Accuracy: 0.9954407294832827\n",
      "Epoch 22: Train Loss: 0.05418577756394039, Train Accuracy: 0.9954407294832827, Val Loss: 0.047125050120733, Val Accuracy: 0.9954407294832827\n",
      "Epoch 23: Train Loss: 0.04984519596804272, Train Accuracy: 0.9954407294832827, Val Loss: 0.0423042027449066, Val Accuracy: 0.9954407294832827\n",
      "Epoch 24: Train Loss: 0.042423772710290825, Train Accuracy: 0.9954407294832827, Val Loss: 0.03893699869513512, Val Accuracy: 0.9954407294832827\n",
      "Epoch 25: Train Loss: 0.038926286453550514, Train Accuracy: 0.9954407294832827, Val Loss: 0.034648751162669876, Val Accuracy: 0.9954407294832827\n",
      "Average Training Accuracy over 25 epochs: 0.9351975683890575\n",
      "Average Validation Accuracy over 25 epochs: 0.9479635258358661\n",
      "Test Loss: 0.692837635676066, Test Accuracy: 0.7239263803680982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnav/anaconda3/envs/research_project/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/arnav/anaconda3/envs/research_project/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/home/arnav/anaconda3/envs/research_project/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6757534308867021, Train Accuracy: 0.5866261398176292, Val Loss: 0.6412490389563821, Val Accuracy: 0.5866261398176292\n",
      "Epoch 2: Train Loss: 0.6274080926721747, Train Accuracy: 0.5866261398176292, Val Loss: 0.5573236617175016, Val Accuracy: 0.5866261398176292\n",
      "Epoch 3: Train Loss: 0.5539684078910134, Train Accuracy: 0.7112462006079028, Val Loss: 0.5054145089604638, Val Accuracy: 0.7325227963525835\n",
      "Epoch 4: Train Loss: 0.4713967632163655, Train Accuracy: 0.7887537993920972, Val Loss: 0.5278292122212324, Val Accuracy: 0.7264437689969605\n",
      "Epoch 5: Train Loss: 0.45718805356459186, Train Accuracy: 0.7993920972644377, Val Loss: 0.4619624465703964, Val Accuracy: 0.8085106382978723\n",
      "Epoch 6: Train Loss: 0.3902643160386519, Train Accuracy: 0.8282674772036475, Val Loss: 0.32616633447733795, Val Accuracy: 0.8647416413373861\n",
      "Epoch 7: Train Loss: 0.33013753592967987, Train Accuracy: 0.8495440729483282, Val Loss: 0.2643240121277896, Val Accuracy: 0.8814589665653495\n",
      "Epoch 8: Train Loss: 0.26626172119920904, Train Accuracy: 0.9012158054711246, Val Loss: 0.2814790694551034, Val Accuracy: 0.8844984802431611\n",
      "Epoch 9: Train Loss: 0.2354991463097659, Train Accuracy: 0.9042553191489362, Val Loss: 0.2003461444242434, Val Accuracy: 0.9224924012158054\n",
      "Epoch 10: Train Loss: 0.22648051719773898, Train Accuracy: 0.9224924012158054, Val Loss: 0.12136221981861374, Val Accuracy: 0.958966565349544\n",
      "Epoch 11: Train Loss: 0.15198966081846843, Train Accuracy: 0.939209726443769, Val Loss: 0.10501108640296893, Val Accuracy: 0.9726443768996961\n",
      "Epoch 12: Train Loss: 0.11845622651956299, Train Accuracy: 0.9574468085106383, Val Loss: 0.03906078077852726, Val Accuracy: 0.9924012158054711\n",
      "Epoch 13: Train Loss: 0.1158806537701325, Train Accuracy: 0.952887537993921, Val Loss: 0.052912377159703865, Val Accuracy: 0.986322188449848\n",
      "Epoch 14: Train Loss: 0.03849048658528111, Train Accuracy: 0.9893617021276596, Val Loss: 0.020047934926961632, Val Accuracy: 0.9954407294832827\n",
      "Epoch 15: Train Loss: 0.02167601434683258, Train Accuracy: 0.9954407294832827, Val Loss: 0.0755730173431485, Val Accuracy: 0.9620060790273556\n",
      "Epoch 16: Train Loss: 0.04151937744410878, Train Accuracy: 0.9893617021276596, Val Loss: 0.011545173855583098, Val Accuracy: 0.9969604863221885\n",
      "Epoch 17: Train Loss: 0.1286045089681548, Train Accuracy: 0.9604863221884499, Val Loss: 0.03547098817811771, Val Accuracy: 0.986322188449848\n",
      "Epoch 18: Train Loss: 0.05999323209239678, Train Accuracy: 0.9817629179331308, Val Loss: 0.019981989171355963, Val Accuracy: 0.9969604863221885\n",
      "Epoch 19: Train Loss: 0.027192890898070553, Train Accuracy: 0.9924012158054711, Val Loss: 0.01001580760136924, Val Accuracy: 0.9984802431610942\n",
      "Epoch 20: Train Loss: 0.008334403963420878, Train Accuracy: 0.9969604863221885, Val Loss: 0.005394196106036278, Val Accuracy: 0.9984802431610942\n",
      "Epoch 21: Train Loss: 0.00668150498743423, Train Accuracy: 0.9984802431610942, Val Loss: 0.009380581988972897, Val Accuracy: 0.9969604863221885\n",
      "Epoch 22: Train Loss: 0.00170696310471447, Train Accuracy: 1.0, Val Loss: 0.005542803364567755, Val Accuracy: 0.9969604863221885\n",
      "Epoch 23: Train Loss: 0.0020793673796685075, Train Accuracy: 0.9984802431610942, Val Loss: 0.0004933284733190455, Val Accuracy: 1.0\n",
      "Epoch 24: Train Loss: 0.0009818584711121564, Train Accuracy: 1.0, Val Loss: 0.00023840204647223635, Val Accuracy: 1.0\n",
      "Epoch 25: Train Loss: 0.00030331253418063915, Train Accuracy: 1.0, Val Loss: 0.00024731466394521044, Val Accuracy: 1.0\n",
      "Average Training Accuracy over 25 epochs: 0.9052279635258358\n",
      "Average Validation Accuracy over 25 epochs: 0.9133130699088146\n",
      "Test Loss: 1.2255665461222331, Test Accuracy: 0.7852760736196319\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "NN1 = SimpleNN()\n",
    "optimizer = optim.Adam(NN1.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train(NN1, optimizer, loss_fn, train_loader, val_loader, epochs=25, device=device)\n",
    "test(NN1, test_loader, device=device)\n",
    "\n",
    "alex_net = CustomAlexNet()\n",
    "optimizer = optim.Adam(alex_net.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train(alex_net, optimizer, loss_fn, train_loader, val_loader, epochs=25, device=device)\n",
    "test(alex_net, test_loader, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5feaeb-1d89-4ea0-9d89-5c7cfae3f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# NN1 = SimpleNN()\n",
    "# optimizer = optim.Adam(NN1.parameters(), lr=0.0001)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# train(NN1, optimizer, loss_fn, train_loader, val_loader, epochs=25, device=device)\n",
    "# test(NN1, test_loader, device=device)\n",
    "\n",
    "# alex_net = CustomAlexNet()\n",
    "# optimizer = optim.Adam(alex_net.parameters(), lr=0.0001)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# train(alex_net, optimizer, loss_fn, train_loader, val_loader, epochs=25, device=device)\n",
    "# test(alex_net, test_loader, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5fcf1-bff7-4929-b939-cd01c8343872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc91485-5b37-484d-a34a-dc49fe3fa9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
